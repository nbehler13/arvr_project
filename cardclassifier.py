# -*- coding: utf-8 -*-
"""CardClassifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-39hKTvkdHKUk8nuMYB5mqG1iAxvk6Sa
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf
import pandas as pd
import xml.etree.ElementTree as ET
import io
import os
import urllib
import cv2
import time
from PIL import Image

from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, ZeroPadding2D, Activation, Add, BatchNormalization, AveragePooling2D
from tensorflow.keras import regularizers, optimizers

import seaborn as sns
from pylab import rcParams
import matplotlib.pyplot as plt
from matplotlib import rc
from pandas.plotting import register_matplotlib_converters
from sklearn.utils import shuffle

# %matplotlib inline
# %config InlineBackend.figure_format='retina'

register_matplotlib_converters()
sns.set(style='whitegrid', palette='muted', font_scale=1.5)

rcParams['figure.figsize'] = 22, 10

RANDOM_SEED = 42

np.random.seed(RANDOM_SEED)
tf.random.set_seed(RANDOM_SEED)

card_path = 'C:/Users/nickl/Pictures/card_dataset_cropped'
snapshots_path = os.path.join(os.path.dirname(__file__), 'snapshots')
BATCHSIZE = 16
EPOCHS = 1
IMG_SIZE = (80, 80)

cropped_train_path = 'C:/Users/nickl/Pictures/card_dataset_cropped/'


def create_model():
    model = Sequential([Conv2D(16, 3, activation='relu', input_shape=(80, 80, 1)),
                        MaxPooling2D(),
                        Dropout(0.3),
                        Conv2D(32, 5, activation='relu'),
                        MaxPooling2D(),
                        Dropout(0.3),
                        Conv2D(64, 3, activation='relu'),
                        MaxPooling2D(),
                        Dropout(0.3),
                        Flatten(),
                        #Dense(512, activation='relu'),
                        Dense(52, activation='softmax')])

activation_function = tf.nn.relu
def create_resnet_model(num_of_layers=50):
    inputs = tf.keras.Input(shape=(80, 80, 1))

    block_2, block_3 = [4, 6]
    if num_of_layers is 101:
        block_2, block_3 = [4, 23]
    elif num_of_layers is 152:
        block_2, block_3 = [8, 36]


    x = ZeroPadding2D((3, 3))(inputs)
    x = Conv2D(64, (7, 7), strides=(2, 2))(x)
    x = BatchNormalization(axis=3)(x)
    x = Activation(activation_function)(x)
    x = MaxPooling2D((3, 3), strides=(2, 2))(x)

    x = conv_block(x, filters=[64, 64, 256], s=1)
    for i in range(3):
        x = id_block(x, [64, 64, 256])

    x = conv_block(x, filters=[128, 128, 512])
    for i in range(block_2):
        x = id_block(x, [128, 128, 512])
    
    x = conv_block(x, filters=[256, 256, 1024])
    for i in range(block_3):
        x = id_block(x, [256, 256, 1024])

    x = conv_block(x, filters=[512, 512, 2048])
    for i in range(3):
        x = id_block(x, [512, 512, 2048])

    x = AveragePooling2D((2,2))(x)
    x = Flatten()(x)
    output = Dense(52, activation=tf.nn.softmax)(x)

    res_net_model = tf.keras.Model(inputs, outputs=output)
    return res_net_model


def conv_block(input_data, filters, s=2):
    f1, f2, f3 = filters

    x = Conv2D(f1, (1, 1), strides=(s,s))(input_data)
    x = BatchNormalization(axis = 3)(x)
    x = Activation(activation_function)(x) 

    x = Conv2D(f2, (3, 3), strides=(1,1), padding = 'same')(x)
    x = BatchNormalization(axis = 3)(x)
    x = Activation(activation_function)(x) 

    x = Conv2D(f3, (1, 1), strides=(1,1), padding = 'valid')(x)
    x = BatchNormalization(axis = 3)(x)

    skip = Conv2D(f3, (1, 1), strides=(s,s), padding = 'valid')(input_data)
    skip = BatchNormalization(axis = 3)(skip)

    x = Add()([x, skip])
    x = Activation(activation_function)(x) 

    return x


def id_block(input_data, filters):
    f1, f2, f3 = filters

    x = Conv2D(f1, (1, 1), strides=(1,1), padding='valid')(input_data)
    x = BatchNormalization(axis = 3)(x)
    x = Activation(activation_function)(x) 

    x = Conv2D(f2, (3, 3), strides=(1,1), padding = 'same')(x)
    x = BatchNormalization(axis = 3)(x)
    x = Activation(activation_function)(x)

    x = Conv2D(f3, (1, 1), strides=(1,1), padding = 'valid')(x)
    x = BatchNormalization(axis = 3)(x)

    x = Add()([x, input_data])
    x = Activation(activation_function)(x) 

    return x


CLASSES_FILE = 'classes.csv'
labels_to_names = pd.read_csv(
    CLASSES_FILE,
    header=None,
    index_col=0
).to_dict()[1]

def setup_for_training():

    TRAIN_ANNOTATIONS_FILE = os.path.join(cropped_train_path, 'annotations.csv')
    trainDF = pd.read_csv(TRAIN_ANNOTATIONS_FILE, names=['image_name', 'class_name']) 


    # for i in range(len(trainDF)):
    #     if i >= 3461:
    #         if trainDF.loc[i, 'class_name'][0] in ['a', 'k', 'j']:
    #             trainDF.drop(i, inplace=True)
    #             i = i-1

    #print(trainDF.shape)
    trainDF = shuffle(trainDF)

    datagen = keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255, 
        horizontal_flip=True, 
        vertical_flip=True,
        rotation_range=360,
        shear_range=10,
        #zoom_range=0.2
    )
    train_generator = datagen.flow_from_dataframe(
        dataframe=trainDF,
        x_col='image_name',
        y_col='class_name',
        class_mode='categorical',
        target_size=IMG_SIZE,
        batch_size=BATCHSIZE,
        color_mode='grayscale'
    )

    cropped_test_path = os.path.join(card_path, "cropped_test")

    TEST_ANNOTATIONS_FILE = os.path.join(card_path, 'annotations.csv')
    testDF = pd.read_csv(TEST_ANNOTATIONS_FILE, names=['image_name', 'class_name']) 

    test_generator = datagen.flow_from_dataframe(
        dataframe=testDF,
        x_col='image_name',
        y_col='class_name',
        class_mode='categorical',
        target_size=IMG_SIZE,
        batch_size=BATCHSIZE,
        color_mode='grayscale'
    )

    return train_generator, test_generator


# def plot_history(history, model_path):
#
#   fig, (ax1, ax2) = plt.subplots(2, tight_layout=True, figsize=(18, 9))
#
#   ax1.plot(history.history['loss'])
#   ax1.plot(history.history['val_loss'])
#   fig.suptitle('model train vs validation\n'+param_text)
#   ax1.set(xlabel='epoch', ylabel='loss')
#   ax1.legend(['train', 'validation'], loc='upper right')
#
#   ax2.plot(history.history['categorical_accuracy'])
#   ax2.plot(history.history['val_categorical_accuracy'])
#   ax2.set(xlabel='epoch', ylabel='accuracy')
#   ax2.legend(['train', 'validation'], loc='upper right')
#
#   plot_path = os.path.join(model_path, "model_eval")
#   fig.savefig(plot_path, format='png', dpi=600)
#   plt.show()


def train_model(use_resnet_model = True):
    train_generator, _ = setup_for_training()
    
    if use_resnet_model:
        model = create_resnet_model()
    else:
        model = create_model()

    optimizer = optimizers.Adam(learning_rate=0.001)
    model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=["accuracy"])
    # print(model.summary())

    model_name = "CardClassifier.h5"

    if use_resnet_model:
        model_name = "CardClassifier_ResNet.h5"

    model_path = os.path.join(card_path, model_name)

    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size

    history = model.fit(x=train_generator,
                        steps_per_epoch=STEP_SIZE_TRAIN,
                        epochs=EPOCHS,
                        #validation_data=test_generator
    )
    model.save(model_path)
    print("Saved model to: %s" % model_path)
    #plot_history(history, model_path)


def predict_model():
    model = tf.keras.models.load_model(os.path.join(card_path, "CardClassifier_ResNet.h5"))
    print(model.summary())

    img_name = os.path.join(card_path, 'cropped_test', "8.jpg")
    img = cv2.imread(img_name)
    img = img/255.0

    plt.axis('off')
    plt.imshow(img)
    plt.show()

    img = img.reshape(-1,80,80,1)

    prediction = model.predict(img)
    print(prediction)
    idx = np.argmax(prediction[0])
    print(idx)
    for key, value in labels_to_names.items():
      if value == idx:
        print(key)
        break


train_model()
predict_model()